{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install --upgrade tensorflow"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import xml.etree.ElementTree as xet\n","from collections import defaultdict\n","from sklearn.cluster import KMeans\n","import pandas as pd\n","import albumentations as A\n","import cv2\n","import random\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf # 2.17.0\n","print(tf.__version__)\n","from tensorflow.keras.layers import Conv2D, Input, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D, Add, concatenate, Lambda\n","from tensorflow.keras.models import Model\n","import struct\n","import importlib.util\n","import sys\n","import os\n","import warnings\n","\n","# Suppress all warnings\n","warnings.filterwarnings('ignore')\n","\n","# Set the random seed for reproducibility\n","random_seed = 42\n","random.seed(random_seed)\n","np.random.seed(random_seed)\n","tf.random.set_seed(random_seed)\n","\n","# Define the path to your script\n","utils_path = '/kaggle/input/project-numberplate/utils.py'\n","\n","# Load the module\n","spec = importlib.util.spec_from_file_location(\"utils\", utils_path)\n","utils = importlib.util.module_from_spec(spec)\n","sys.modules[\"utils\"] = utils\n","spec.loader.exec_module(utils)\n","from utils import WeightReader, freeze_yolov3_layers, process_outputs, draw_boxes, make_yolov3_model, CustomLoss, _conv_block, yolo_head, trueBoundingBoxTransformer, YOLOv3Metrics, crop_and_resize, bbox_to_center_and_size, img_bbox_resize, calculate_iou, multi_output_image_generator"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Load the df if saved earlier\n","#df = pd.read_pickle('/kaggle/input/project-numberplate/data.pkl')\n","#df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# For reproducibility, mention folder paths in the below order\n","# Directory where your files are located\n","folder_path0 = '/kaggle/input/project-numberplate/image_data/image_data/State-wise_OLX'\n","folder_path1 = '/kaggle/input/project-numberplate/image_data/image_data/google_images'\n","folder_path2 = '/kaggle/input/project-numberplate/image_data/image_data/more_data'\n","folder_path3 = '/kaggle/input/project-numberplate/image_data/image_data/video_images'\n","\n","# List of directories where your files are located\n","source_dirs = [folder_path0, folder_path1, folder_path2, folder_path3]\n","\n","# Initialize lists for image and xml files\n","image_files = []\n","xml_files = []\n","\n","# Gather files from all source directories\n","for folder_path in source_dirs:\n","    image_files.extend([os.path.join(folder_path, f) for f in os.listdir(folder_path) if os.path.splitext(f)[1].lower() in ['.png', '.jpeg', '.jpg']])\n","    xml_files.extend([os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.xml')])\n","\n","# Create defaultdict to group files by base name\n","file_groups = defaultdict(lambda: {'image': None, 'xml': None})\n","\n","# Fill defaultdict with image files\n","for image_file in image_files:\n","    base_name = os.path.splitext(os.path.basename(image_file))[0]  # Get base name without extension\n","    file_groups[base_name]['image'] = image_file\n","\n","# Fill defaultdict with xml files\n","for xml_file in xml_files:\n","    base_name = os.path.splitext(os.path.basename(xml_file))[0]  # Get base name without extension\n","    file_groups[base_name]['xml'] = xml_file\n","\n","# Filter out groups where both image and xml files are present\n","file_pairs = [(group['image'], group['xml']) for group in file_groups.values() if group['image'] and group['xml']]\n","\n","# Displaying the result\n","print(len(file_pairs))\n","\n","data_dict = {'img':[], 'targ':[]}\n","for img, filename in file_pairs:\n","    tree = xet.parse(filename)\n","    root = tree.getroot()\n","    bboxes = []\n","    for object_ in root.findall('object'):\n","        labels = object_.find('bndbox')\n","        if labels is not None:\n","            xmin = int(labels.find('xmin').text)\n","            ymin = int(labels.find('ymin').text)\n","            xmax = int(labels.find('xmax').text)\n","            ymax = int(labels.find('ymax').text)\n","            bboxes.append(bbox_to_center_and_size(xmin, ymin, xmax, ymax))\n","    img_, out_bbox = img_bbox_resize(img, bboxes, targetsize = 608)\n","    data_dict['img'].append(img_)\n","    data_dict['targ'].append(out_bbox)\n","\n","df = pd.DataFrame(data_dict)\n","rows_to_drop = []\n","for m in range(df.shape[0]):\n","    bboxes = df.iloc[m,1]\n","    for bbox in bboxes:\n","        x_center, y_center, w, h = bbox\n","        x_min, y_min, x_max, y_max = x_center - w/2, y_center - h/2, x_center + w/2, y_center + h/2\n","        if x_min < 0 or y_min < 0 or x_max > 1 or y_max > 1:\n","            rows_to_drop.append(m)\n","df.drop(rows_to_drop, inplace=True)\n","df.reset_index(drop=True, inplace=True)\n","df.shape\n","#Save the dataframe for direct loading of preprocessed data\n","#df.to_pickle('data.pkl') "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X = df[['img']]\n","y = df['targ']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n","train_df = pd.concat([X_train, y_train], axis=1)\n","test_df = pd.concat([X_test, y_test], axis=1)\n","train_df.reset_index(drop=True, inplace=True)\n","test_df.reset_index(drop=True, inplace=True)\n","train_df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test_df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Define the transformation pipeline with bbox_params\n","transform = A.Compose([\n","    A.OneOf([\n","        A.Resize(height=203, width=203, p= 1.0),  # Resize to a smaller size to simulate distance\n","        A.NoOp(p=1.0)\n","    ], p=1.0),\n","\n","    A.PadIfNeeded(min_height=608, min_width=608, border_mode=cv2.BORDER_CONSTANT, value=[0, 0, 0]),  # Pad back to original size\n","    A.Rotate(limit=10, p=0.5),\n","    A.RandomBrightnessContrast(p=0.5),\n","    A.HueSaturationValue(p=0.5),\n","    A.GaussNoise(p=0.2),\n","    A.MotionBlur(p=0.2),\n","    A.Perspective(scale=(0.05, 0.1), p=0.5),\n","], bbox_params=A.BboxParams(format='yolo', min_area=0.1, min_visibility=0.3, label_fields=['labels']))\n","\n","\n","# Generate multiple augmented images\n","ini_size = train_df.shape[0]\n","for m in range(ini_size):\n","    image = train_df.iloc[m,0]\n","    bboxes = train_df.iloc[m,1]\n","    labels = [0]*len(bboxes) #dummy labels\n","    num_augmentations = 1\n","    for i in range(num_augmentations):\n","        transformed = transform(image=image, bboxes=bboxes, labels=labels)\n","        transformed_image = transformed['image']\n","        transformed_bboxes = transformed['bboxes']\n","        new_row = {'img': transformed_image, 'targ': transformed_bboxes}\n","        train_df.loc[len(train_df)] = new_row"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ini_size = train_df.shape[0]\n","for m in range(ini_size):\n","    image = train_df.iloc[m,0]\n","    bboxes = train_df.iloc[m,1]\n","    num_augmentations = 1\n","    for i in range(num_augmentations):\n","        if len(bboxes) > 0:\n","            resized_image, transformed_bbox, valid = crop_and_resize(image, bboxes[0], output_size=(608, 608), zoom_range=(1.4, 2.8), thresh_area= (0.01, 0.2))\n","            if valid:\n","                new_row = {'img': resized_image, 'targ': [transformed_bbox]}\n","                train_df.loc[len(train_df)] = new_row"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["normalized_bboxes_list = []\n","for a in train_df.iloc[:,1]:\n","    for k in a:\n","        normalized_bboxes_list.append(k)\n","normalized_bboxes = np.array(normalized_bboxes_list)\n","normalized_wh = normalized_bboxes[:,2:]\n","cluster_anchors = {}\n","average_iou = []\n","for num_anchors in range(1,16):\n","    kmeans = KMeans(n_clusters=num_anchors, random_state=42, verbose = 0).fit(normalized_wh)\n","    anchor_boxes = kmeans.cluster_centers_\n","    cluster_anchors[num_anchors] = anchor_boxes\n","# Evaluate the anchor boxes\n","    ious = []\n","    for bbox in normalized_wh:\n","        best_iou = 0\n","        for anchor in anchor_boxes:\n","            iou = calculate_iou(bbox, anchor)\n","            if iou > best_iou:\n","                best_iou = iou\n","        ious.append(best_iou)\n","    average_iou.append(np.mean(ious))\n","    \n","plt.figure(figsize=(10, 6))\n","plt.plot(range(1,16),average_iou, marker='o', color='blue')\n","plt.title('Average IoU vs. Number of Clusters (Anchor Boxes)')\n","plt.ylabel('Average IoU')\n","plt.xlabel('Clusters')\n","plt.xticks(range(1, 16))\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["anchors = cluster_anchors[4]\n","#np.save('anchors.npy', anchors)\n","# Load the NumPy array from the file\n","#anchors = np.load('/kaggle/input/project-numberplate/anchors.npy')\n","#print(\"Loaded anchors:\")\n","print(anchors)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["batch_size = 32\n","# Calculate the number of samples needed\n","num_samples = len(train_df)\n","remainder = num_samples % batch_size\n","if remainder != 0:\n","    samples_needed = batch_size - remainder\n","\n","    # Randomly sample from the DataFrame\n","    random_samples = train_df.sample(n=samples_needed, replace=True, random_state=42)\n","\n","    # Append the samples to the original DataFrame\n","    train_df = pd.concat([train_df, random_samples]).reset_index(drop=True)\n","\n","print(f\"New number of samples: {len(train_df)}\")  # Should be a multiple of batch_size"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model = make_yolov3_model()\n","#model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["weight_reader = WeightReader('/kaggle/input/project-numberplate/yolov3.weights')\n","weight_reader.load_weights(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Input tensor\n","inputs = model.input\n","\n","x = model.get_layer('leaky_80').output\n","yolo_82 = _conv_block(x, [{'filter':  20, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False)\n","\n","x = model.get_layer('leaky_92').output\n","yolo_94 = _conv_block(x, [{'filter': 20, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False)\n","\n","x = model.get_layer('leaky_104').output\n","yolo_106 = _conv_block(x, [{'filter': 20, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False)\n","\n","\n","# Create a new model with the modified architecture\n","model = Model(inputs=inputs, outputs=[yolo_82, yolo_94, yolo_106])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Freeze all layers except those connected to outputs\n","for layer in model.layers:\n","    layer.trainable = False\n","# Ensure the output layers are trainable\n","model.get_layer('conv_81').trainable = True\n","model.get_layer('conv_93').trainable = True\n","model.get_layer('conv_105').trainable = True\n","\n","custom_loss13 = CustomLoss(anchors = anchors, box_weight = 10.0)\n","custom_loss26 = CustomLoss(anchors = anchors, box_weight = 10.0)\n","custom_loss52 = CustomLoss(anchors = anchors, box_weight = 10.0)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate =0.001)\n","model.compile(optimizer = optimizer, loss = [custom_loss13, custom_loss26, custom_loss52])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["transformer = trueBoundingBoxTransformer(anchors, target_sizes = [19,38,76])\n","y_13, y_26, y_52 = transformer.transform(train_df)\n","y_13.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["batch_size = 32\n","steps_per_epoch = len(train_df) // batch_size\n","train_gen = multi_output_image_generator(train_df, y_13, y_26, y_52, batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["history = model.fit(train_gen, steps_per_epoch=steps_per_epoch, epochs=10, initial_epoch = 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for i, layer in enumerate(model.layers):\n","    if i > 54:  # Assuming the index starts from 0\n","        layer.trainable = True\n","optimizer = tf.keras.optimizers.Adam(learning_rate =0.0001)\n","model.compile(optimizer = optimizer, loss = [custom_loss13, custom_loss26, custom_loss52])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["history = model.fit(train_gen, steps_per_epoch=steps_per_epoch, epochs=40, initial_epoch = 10)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test_images = np.stack(test_df['img'].values)\n","ytest_13, ytest_26, ytest_52 = transformer.transform(test_df)\n","Metrics = YOLOv3Metrics([anchors,anchors,anchors], confidence_thresh=0.5, iou_thresh = 0.7, NMS_thresh=0.0)\n","test_images.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["metrics_ = {'TP':0,'FP':0,'FN':0}\n","for m in range(test_images.shape[0]):\n","    pred = model.predict(test_images[m:m+1], verbose=0)\n","    tp, fp, fn = Metrics.metrics(pred, ytest_13[m:m+1])\n","    metrics_['TP'] += tp\n","    metrics_['FP'] += fp\n","    metrics_['FN'] += fn\n","metrics_"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.save('model_40.keras')"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5376025,"sourceId":9103133,"sourceType":"datasetVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
